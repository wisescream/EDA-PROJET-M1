# ğŸ¬ Analyse de Sentiments - Critiques de Films AllocinÃ©

Projet d'analyse de sentiments sur le dataset AllocinÃ© utilisant des modÃ¨les classiques de Machine Learning et le modÃ¨le CamemBERT (Deep Learning).

## ğŸ“‹ Description

Ce projet implÃ©mente une analyse complÃ¨te de sentiments sur des critiques de films en franÃ§ais. Il comprend :

- **PrÃ©traitement de donnÃ©es** : nettoyage, lemmatisation avec SpaCy
- **Analyse exploratoire (EDA)** : word clouds, distributions, statistiques
- **ModÃ¨les classiques** : Naive Bayes, SVM, Random Forest, RÃ©gression Logistique
- **ModÃ¨le Deep Learning** : Fine-tuning de CamemBERT
- **Ã‰valuation et comparaison** des performances

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- 8GB RAM minimum (pour l'entraÃ®nement de BERT)
- Git

### Configuration de l'environnement

1. **Cloner le repository**
```bash
git clone <votre-repo-url>
cd EDA
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv .venv
```

3. **Activer l'environnement virtuel**

**Windows:**
```bash
.venv\Scripts\activate
```

**Linux/Mac:**
```bash
source .venv/bin/activate
```

4. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

5. **TÃ©lÃ©charger le modÃ¨le SpaCy franÃ§ais**
```bash
python -m spacy download fr_core_news_sm
```

6. **Installer le kernel Jupyter**
```bash
python -m ipykernel install --user --name=eda_venv --display-name="Python (EDA)"
```

## ğŸ““ Utilisation

### Lancer Jupyter Notebook

```bash
jupyter notebook
```

Ensuite :
1. Ouvrir `sentiment_analysis.ipynb`
2. SÃ©lectionner le kernel **"Python (EDA)"** dans le menu
3. ExÃ©cuter les cellules dans l'ordre

### Structure du Notebook

1. **Collecte des donnÃ©es** : Chargement du dataset AllocinÃ© (200,000 avis)
2. **PrÃ©traitement** : Nettoyage et lemmatisation
3. **EDA** : Visualisations et statistiques
4. **ModÃ©lisation classique** : EntraÃ®nement et Ã©valuation
5. **CamemBERT** : Fine-tuning et comparaison
6. **InterprÃ©tation** : Analyse des rÃ©sultats

## ğŸ“Š Dataset

- **Source** : Hugging Face Datasets - `allocine`
- **Taille** : 200,000 critiques de films
- **Classes** : Binaire (positif/nÃ©gatif)
- **Langue** : FranÃ§ais

Le dataset est automatiquement tÃ©lÃ©chargÃ© lors de la premiÃ¨re exÃ©cution.

## ğŸ”§ Configuration CPU/GPU

Le notebook dÃ©tecte automatiquement si CUDA est disponible :

- **GPU disponible** : Utilise le GPU pour l'entraÃ®nement BERT (plus rapide)
- **CPU uniquement** : RÃ©duit automatiquement la taille du dataset (200 avis pour la dÃ©mo)

Pour modifier la taille du dataset sur CPU, ajustez la variable `sample_size` dans la cellule correspondante.

## ğŸ“ˆ RÃ©sultats Attendus

Les modÃ¨les classiques atteignent gÃ©nÃ©ralement :
- **Naive Bayes** : ~85-88% d'accuracy
- **SVM** : ~88-91% d'accuracy
- **Random Forest** : ~85-88% d'accuracy
- **RÃ©gression Logistique** : ~88-90% d'accuracy

CamemBERT peut atteindre :
- **CamemBERT fine-tunÃ©** : ~92-95% d'accuracy (avec GPU et dataset complet)

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.x**
- **Pandas & NumPy** : Manipulation de donnÃ©es
- **Scikit-learn** : ModÃ¨les ML classiques
- **SpaCy** : Lemmatisation franÃ§aise
- **Transformers (Hugging Face)** : CamemBERT
- **PyTorch** : Deep Learning
- **Matplotlib & Seaborn** : Visualisations
- **WordCloud** : Nuages de mots

## ğŸ“ Structure du Projet

```
EDA/
â”‚
â”œâ”€â”€ .venv/                      # Environnement virtuel
â”œâ”€â”€ sentiment_analysis.ipynb    # Notebook principal
â”œâ”€â”€ allocine_raw.csv           # Dataset (gÃ©nÃ©rÃ© automatiquement)
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ README.md                  # Ce fichier
â””â”€â”€ .gitignore                # Fichiers Ã  ignorer par Git
```

## âš ï¸ Notes Importantes

### EntraÃ®nement sur CPU

Si vous utilisez uniquement le CPU :
- Le dataset est rÃ©duit Ã  200 avis pour CamemBERT
- L'entraÃ®nement prendra ~2-5 minutes par Ã©poque
- Pour un dataset complet, utilisez un GPU ou rÃ©duisez `num_train_epochs`

### Gestion de la MÃ©moire

Pour Ã©viter les problÃ¨mes de mÃ©moire :
- Fermez les autres applications
- RÃ©duisez `sample_size` si nÃ©cessaire
- RedÃ©marrez le kernel Jupyter entre les expÃ©rimentations

## ğŸ” DÃ©pannage

### Erreur "df is not defined"
- ExÃ©cutez d'abord toutes les cellules d'import et de chargement de donnÃ©es

### Erreur "No module named 'accelerate'"
```bash
pip install accelerate>=0.26.0
```

### Erreur SpaCy
```bash
python -m spacy download fr_core_news_sm
```

### Kernel non trouvÃ©
```bash
python -m ipykernel install --user --name=eda_venv
```

## ğŸ“ License

Ce projet est sous licence MIT.

## ğŸ‘¤ Auteur

Rayane Ibnatik

## ğŸ“š RÃ©fÃ©rences

- [Dataset AllocinÃ©](https://huggingface.co/datasets/allocine)
- [CamemBERT](https://huggingface.co/camembert-base)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [SpaCy](https://spacy.io/)
